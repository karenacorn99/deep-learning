{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hiei9XnNIfMr",
        "apUjM5L5Kznc",
        "g-Ozxc0tLBv2",
        "YiHe1260nJ7W",
        "avc-sr95LGDx",
        "WMWEBYlPLIt2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convoluation Neural Network\n"
      ],
      "metadata": {
        "id": "hiei9XnNIfMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each pixel in an image is associated with one or multiple numerical values, depending whether it black-and-white or colored. \n",
        "\n",
        "Previously...\n",
        "- flattening values corresponding to each pixel into 1-d vetorrs\n",
        "- spatial structure is discarded\n",
        "- MLP is invariant to order of features, similar results are obtained regardless of whether we preserve order or not\n",
        "\n",
        "Motivation\n",
        "- want to leverage prior knowledge that nearby pixels are typically related to each other\n",
        "\n",
        "CNN\n",
        "- sample-efficient in achieving accurate model\n",
        "- computationally efficient because: 1) require fewer parameters than fully-connected architectures; 2) convolutions are easy to parrallelize across GPU cores"
      ],
      "metadata": {
        "id": "cQy_olqII04N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From Fuly-Connected Layers to Convoluations"
      ],
      "metadata": {
        "id": "apUjM5L5Kznc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spatial invariance: Waldo looks the same regardless of his location\n",
        "Desiderata:\n",
        "- Translation invariance: in the earliest layer, the network should respond similarly to the same patch, regardless of where it appears in the image\n",
        "- Locality principal: the earliest layers of the network should focus on local regions, without regard for the contents of the image in distant regions. These local representations can be aggregated to make predictions at the whole image level"
      ],
      "metadata": {
        "id": "yWXpFDjXU8--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- convolution kernel / filter \n",
        "- channels / feature maps: allow models to capture multiple aspects of an image at each spatial location"
      ],
      "metadata": {
        "id": "QDoWmVsjU_EZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convoluations for Images"
      ],
      "metadata": {
        "id": "g-Ozxc0tLBv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-Correlation Operation**\n",
        "\n",
        "An input tensor and a kernel tensor are combined to produce an output tensor through a cross-correlation operation\n"
      ],
      "metadata": {
        "id": "YUJMAT6CS9nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# input tensor X, kernel tensor K\n",
        "def corr2d(X, K): \n",
        "  \"\"\"Compute 2D cross-correlation\"\"\"\n",
        "  h, w = K.shape\n",
        "  Y = torch.zeros(X.shape[0] - h + 1, X.shape[1] - w + 1)\n",
        "  for i in range(Y.shape[0]):\n",
        "    for j in range(Y.shape[1]):\n",
        "      # element-wise multiplication\n",
        "      Y[i, j] = (X[i:i + h, j:j+w] * K).sum()\n",
        "  return Y"
      ],
      "metadata": {
        "id": "yyx6F-8gLDPO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(9).reshape((3,3))\n",
        "K = torch.arange(4).reshape((2,2))\n",
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkuGEyeub4jz",
        "outputId": "9cd4553c-d206-4560-ff05-adb87b5fad0d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 25.],\n",
              "        [37., 43.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Layers**\n",
        "\n",
        "A convolutional layer cross-correlates the input and kernel and adds a scalar bias to produce an output.\n",
        "\n",
        "Parameters:\n",
        "- kernel (typically randomly initialized)\n",
        "- scalar bias"
      ],
      "metadata": {
        "id": "sLr8jZGJdUxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Conv2D(nn.Module):\n",
        "  def __init__(self, kernel_size):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.rand(kernel_size)) # torch.rand(): uniform distribution on [0,1)\n",
        "    self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return corr2d(x, self.weight) + self.bias\n"
      ],
      "metadata": {
        "id": "VX4FUJbfb4l6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Edge Detection in Images**\n",
        "\n",
        "A simple application of a convolutonal layer: detecting the edge of an object in an image by finding the location of the pixel change."
      ],
      "metadata": {
        "id": "HBvPkCh8ex2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, construct an image of 6x8 pixels. Middle 4 columns are black (0) and the remaining are white (1)."
      ],
      "metadata": {
        "id": "PTycCGBse_ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so96WsTDereF",
        "outputId": "49628937-22a6-4cca-c6c6-7e374c3cce42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, construct a kernel K with a height of 1 and a width of 2. When we perform cross-correlation operation, if the horizontally adjacent elements are the same, the output is 0. Otherwise, the output is non-zero. "
      ],
      "metadata": {
        "id": "wQfNYOGufVQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[1.0, -1.0]])"
      ],
      "metadata": {
        "id": "NX2GW_V8fUn5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gHyjMLPgGTQ",
        "outputId": "648ea23f-3b15-47ec-f780-6169443acb27"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the kenel to the transposed image, it vanishes. The kernel K only deteects vertical edges."
      ],
      "metadata": {
        "id": "iu7EJm0ZgbcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X.t(), K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qujjIpSzgZrP",
        "outputId": "da9d32d3-a8fc-4314-b69c-5ccc83252499"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play around."
      ],
      "metadata": {
        "id": "ksooRh2Mgkig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(6,8)\n",
        "X[2:5, 2:6] = 0\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKE1hoXgGlB",
        "outputId": "5efe0cac-e7c3-4775-f4fa-a391e38d1d2a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel for detecting horizontal edges."
      ],
      "metadata": {
        "id": "HANH-L6QiAfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[1.0],\n",
        "                  [-1.0]])"
      ],
      "metadata": {
        "id": "RrZ7LwFjgmRD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLz9eZdsgmWw",
        "outputId": "6aa9786a-91b4-4607-acef-bc5acbb0f770"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "        [ 0.,  0., -1., -1., -1., -1.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laplacian edge detector."
      ],
      "metadata": {
        "id": "n8V6p1jSiFbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[0.0,1.0,0.0],\n",
        "                  [1.0,-4.0,1.0],\n",
        "                  [0.0,1.0,0.0]])"
      ],
      "metadata": {
        "id": "lXx267uBiEvW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYA63edniE36",
        "outputId": "39fae4fe-fcbb-4380-ed65-f4108b6ddda1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0., -1., -1., -1., -1.,  0.],\n",
              "        [-1.,  2.,  1.,  1.,  2., -1.],\n",
              "        [-1.,  1.,  0.,  0.,  1., -1.],\n",
              "        [-1.,  2.,  1.,  1.,  2., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vertical Sobel edge detector."
      ],
      "metadata": {
        "id": "NKaoGNGyjAyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[-1.0,0.0,1.0],\n",
        "                  [-2.0,0.0,2.0],\n",
        "                  [-1.0,0.0,1.0]])"
      ],
      "metadata": {
        "id": "DJ4aadW4iE8O"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYCVaLzcjMe4",
        "outputId": "91fbf161-4450-4a8b-8705-280c8e863315"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1., -1.,  0.,  0.,  1.,  1.],\n",
              "        [-3., -3.,  0.,  0.,  3.,  3.],\n",
              "        [-4., -4.,  0.,  0.,  4.,  4.],\n",
              "        [-3., -3.,  0.,  0.,  3.,  3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning a Kernel**\n",
        "Example using built-in class for 2d convoluttional layers and ignore the bias."
      ],
      "metadata": {
        "id": "c8cv28EgjSQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "X = X.reshape((1,1,6,8)) # 4-d input (example, channel, height, width)\n",
        "Y = Y.reshape((1,1,6,7))\n",
        "lr = 3e-2\n",
        "\n",
        "for i in range(10):\n",
        "  Y_hat = conv2d(X)\n",
        "  l = (Y_hat - Y) ** 2\n",
        "  conv2d.zero_grad()\n",
        "  l.sum().backward()\n",
        "  # update kernel \n",
        "  conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "  if (i + 1) % 2 == 0:\n",
        "    print(f'epoch {i + 1}, loss{l.sum():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWKHpBRQLFuI",
        "outputId": "1b751374-d4a9-4fcf-83f1-3d8d1895422e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss10.030\n",
            "epoch 4, loss2.074\n",
            "epoch 6, loss0.508\n",
            "epoch 8, loss0.151\n",
            "epoch 10, loss0.052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d.weight.data.reshape(1,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxarAGVunXHf",
        "outputId": "b69e2f2b-a7b7-412b-edc4-0dd323e54dc1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9629, -1.0070]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional layer output is sometimes called a *feature map*, as it can be regarded as the learned representations (features) in the spatial dimensions (eg width & height) to the subsequent layer. \n",
        "\n",
        "In CNNs, for any element x of some layer, its receptive field refers to all the elements (from all the previous layers) that may affect the calculation of x during forward propagation. Receptive field may be larger than the actual size of the input."
      ],
      "metadata": {
        "id": "XyJSRS_un7BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding & Striding\n",
        "\n",
        "Since kernels generally have width and height greater than 1, after applying many successive convolutions, we tend up wind up with outputs that are considerably smaller than input. *Padding* is the most popular tool for handling this issue.\n",
        "\n",
        "In other cases, we want reduce the dimensionality drastically. *Strided convolutions* are a popular technique that can help in these instances."
      ],
      "metadata": {
        "id": "YiHe1260nJ7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Padding**\n",
        "\n",
        "In many cases, we want to set padding height/width to kernel height/width - 1 to give the input and output the same height and width.\n",
        "\n",
        "CNNs commonly use convolution kernels with odd height and weight values. \n",
        "\n",
        "Benefit: pad the same number of rows on top and bottom, and the same number of columns on left and right\n",
        "\n"
      ],
      "metadata": {
        "id": "oAVl3iPwN7sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "def comp_conv2d(conv2d, X):\n",
        "  # (1,1) -> batch_sze = 1, num_channels = 1\n",
        "  X = X.reshape((1,1) + X.shape)\n",
        "  Y = conv2d(X)\n",
        "  # exclude first 2 dimensions: examples and channels\n",
        "  return Y.reshape(Y.shape[2:])"
      ],
      "metadata": {
        "id": "fxrUh3HfnU-t"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh1fDcMkPjme",
        "outputId": "114e08a3-086e-4664-8ea6-3b4c3f84d98c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the height and width of the convolution kernel are different, we can make the output and input have the same height and weight by setting different paddings numbers."
      ],
      "metadata": {
        "id": "QEtOlPerP9Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(5,3), padding=(2,1))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiky7wgvPjpe",
        "outputId": "efbee1e1-fe0d-4239-cbd2-8229494fe9a5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stride**\n",
        "\n",
        "Reduce resolution of the output.\n",
        "\n",
        "In practice, we rarely use inhomogeneous strides or padding."
      ],
      "metadata": {
        "id": "5pbfaY0aQUcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUfSXEVuPj3Y",
        "outputId": "67132958-7475-4030-d4dd-2708e5d8620d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRFo5aQcQ3kL",
        "outputId": "d49dbfd2-f21e-4b40-b497-c47068ae2583"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Input and Multiple Output Channels\n",
        "\n",
        "Example: RGB channels\n",
        "\n",
        "When the input data contain multiple channels, we need to construct a convolution kernel with the same number of input channels as the input data.\n",
        "\n",
        "Apply kernel to each channel, sum over the channel outputs."
      ],
      "metadata": {
        "id": "avc-sr95LGDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Input Channels**\n",
        "\n"
      ],
      "metadata": {
        "id": "jTOmWpd-Udox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "id": "ivkeTWQNVB8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from d2l import torch as d2l\n",
        "def corr2d_multi_in(X, K):\n",
        "  return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
      ],
      "metadata": {
        "id": "ifeP9eAYLISz"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[[0.0, 1.0, 2.0], \n",
        "                   [3.0, 4.0, 5.0], \n",
        "                   [6.0, 7.0, 8.0]],\n",
        "                   [[1.0, 2.0, 3.0], \n",
        "                    [4.0, 5.0, 6.0], \n",
        "                    [7.0, 8.0, 9.0]]])\n",
        "K = torch.tensor([[[0.0, 1.0], \n",
        "                   [2.0, 3.0]], \n",
        "                  [[1.0, 2.0], \n",
        "                   [3.0, 4.0]]])\n",
        "corr2d_multi_in(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcanJzKJUyvZ",
        "outputId": "67872d50-7bab-4d44-dad2-284c3c2cd84d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  72.],\n",
              "        [104., 120.]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Output Channels**\n",
        "\n",
        "It is essential to have multiple channels at each layer. In popular architectures, we increase the channel dimension as we go higher up in the neural network, typically downsampling to trade off spatial resolution for greater channel depth. "
      ],
      "metadata": {
        "id": "zYVNCKPrVOPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "  return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
      ],
      "metadata": {
        "id": "-tQQbh5CUy0W"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([torch.tensor([[1,2,3],[4,5,6]]), torch.tensor([[-1,-2,-3],[-4,-5,-6]])], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF6L7nphUy3X",
        "outputId": "1fadb22e-ee1d-4c1e-8c1a-7851bbe5e82e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3],\n",
              "         [ 4,  5,  6]],\n",
              "\n",
              "        [[-1, -2, -3],\n",
              "         [-4, -5, -6]]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([torch.tensor([[1,2,3],[4,5,6]]), torch.tensor([[-1,-2,-3],[-4,-5,-6]])], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6SCrOntWfPi",
        "outputId": "92c419e5-0780-4527-cded-6a89335bbc6c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3],\n",
              "         [-1, -2, -3]],\n",
              "\n",
              "        [[ 4,  5,  6],\n",
              "         [-4, -5, -6]]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.stack((K, K + 1, K + 2), 0)\n",
        "K.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4RjOjoQWjzq",
        "outputId": "2fcbda9c-eabd-468d-b0f5-199bb98ca9e1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d_multi_in_out(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIBwwcvtWmYE",
        "outputId": "39b8b28d-d8ca-4ab6-f77c-8f2b7f26097d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 56.,  72.],\n",
              "         [104., 120.]],\n",
              "\n",
              "        [[ 76., 100.],\n",
              "         [148., 172.]],\n",
              "\n",
              "        [[ 96., 128.],\n",
              "         [192., 224.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1x1 Convolutional Layer**\n",
        "\n",
        "Each element in the output is derived from a linear combination of elements at the same position in the input image. Each 1x1 convolutional layer is a fully-connected layer applied at every single pixel location."
      ],
      "metadata": {
        "id": "fjZGXUzrW9W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "  c_i, h, w = X.shape\n",
        "  c_o = K.shape[0]\n",
        "  X = X.reshape((c_i, h * w))\n",
        "  K = K.reshape((c_o, c_i))\n",
        "  # matrix multiplication\n",
        "  Y = torch.matmul(K, X)\n",
        "  return Y.reshape((c_o, h, w))"
      ],
      "metadata": {
        "id": "DDQkprj9W8vq"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.normal(0, 1, (3, 3, 3))\n",
        "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
        "\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "\n",
        "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
      ],
      "metadata": {
        "id": "wEQkHLFbZI0f"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pooling\n",
        "\n",
        "As we process images, we want to gradually reduce the spatial resolution of ourr hidden representations, aggregating information so that the higher up we go in the network, the larger the receptive field (in the input) to which each hidden is sensitive.\n",
        "\n",
        "Purposes:\n",
        "- Mitigating the sensitivity of convolutional layers to location\n",
        "- Spatially downsampling representations"
      ],
      "metadata": {
        "id": "WMWEBYlPLIt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maximum Pooling & Average Pooling**\n",
        "\n",
        "Pooling operators consist of a fixed-shape window that is slid over all regions in the input according to its stride, computing a single output for each location traversed by the fixed-shape *pooling window*. Unlinke cross-correlation computation, pooling layer contain no parameter. These operations are called *maximum pooling* and *average pooling*."
      ],
      "metadata": {
        "id": "eDiHVl2Zb0f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
        "            elif mode == 'avg':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
        "    return Y"
      ],
      "metadata": {
        "id": "Mn02FnzALLVu"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "pool2d(X, (2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktZglAXUdvJf",
        "outputId": "61c04e51-e6ce-47a4-e5ea-8e67f51bd982"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 5.],\n",
              "        [7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d(X, (2, 2), 'avg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF7lz7yYdvM3",
        "outputId": "05926c61-fca7-44fa-f84f-b654c8e64406"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Padding and Stride**\n",
        "\n",
        "As with convolutional layers, pooling layers can also change the output shape."
      ],
      "metadata": {
        "id": "-_fUjlQad1sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIp5QImnd1LZ",
        "outputId": "9678ee4d-bee6-4820-8fc1-9e4be60ce272"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d(3)\n",
        "pool2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTu7X7qAd1O4",
        "outputId": "72de9628-203d-49f3-90e5-27ae6137b4bd"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M46MO5heeMWC",
        "outputId": "e085fa7f-b850-4cdf-a69c-fb17ba27399b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[10.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1TTgGc5d1Sp",
        "outputId": "df0681df-5bbc-4773-f93c-09741021952e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fubR8GOAeS6z",
        "outputId": "1f94bbc0-a0aa-44f0-e378-26141cf87847"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Channels**\n",
        "\n",
        "When processing multi-channel input data, the pooling layer pools each input channel separately, rather than summing the inputs up over channels as in a convolutional layer. This means that the number of output channels for the pooling layer is the same as the number of input channels. "
      ],
      "metadata": {
        "id": "o3AybXeNeVnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.cat((X, X + 1), 1)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEJYDrTGeUhA",
        "outputId": "1f15a76d-e89a-4c4e-c982-d0d926c7fb43"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]],\n",
              "\n",
              "         [[ 1.,  2.,  3.,  4.],\n",
              "          [ 5.,  6.,  7.,  8.],\n",
              "          [ 9., 10., 11., 12.],\n",
              "          [13., 14., 15., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFm_oFKWe90N",
        "outputId": "fcddc7ab-5211-4ec8-c509-f8853a5129ce"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]],\n",
              "\n",
              "         [[ 6.,  8.],\n",
              "          [14., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convoluation Neural Networks Example: LeNet\n",
        "\n",
        "Assemble a fully-functional CNN!\n",
        "\n"
      ],
      "metadata": {
        "id": "fCikSurQLLu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet consists of 2 parts:\n",
        "- a convolutional encoder consisting of two convolutional layers\n",
        "- a dense block consisting of three fully-connected layers\n",
        "\n",
        "The basic units in each convolutional block are a convolutional layer, a sigmoid activation function, and a subsequent average pooling operation. (max pooling and relu work better, but not discovered yet)"
      ],
      "metadata": {
        "id": "kK6a1o7QlauP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
        "    nn.Linear(120, 84), nn.Sigmoid(),\n",
        "    nn.Linear(84, 10))"
      ],
      "metadata": {
        "id": "KoJRFV2FLO6F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-iD1In8mkpy",
        "outputId": "dcdb0daf-774d-4587-abf7-c8a21e8b243d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (1): Sigmoid()\n",
              "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (4): Sigmoid()\n",
              "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (8): Sigmoid()\n",
              "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (10): Sigmoid()\n",
              "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfg1rl9imlQ1",
        "outputId": "ade4d265-e8b0-405f-ba88-dc6bd2284a67"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
            "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
            "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
            "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
            "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
            "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
            "Flatten output shape: \t torch.Size([1, 400])\n",
            "Linear output shape: \t torch.Size([1, 120])\n",
            "Sigmoid output shape: \t torch.Size([1, 120])\n",
            "Linear output shape: \t torch.Size([1, 84])\n",
            "Sigmoid output shape: \t torch.Size([1, 84])\n",
            "Linear output shape: \t torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from d2l import torch as d2l\n",
        "batch_size = 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
      ],
      "metadata": {
        "id": "h3hcWoXfmsq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNbbuMaSoroo",
        "outputId": "5da69ee1-3c0e-4fc2-a51a-6d19f8226618"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fb593f1a590>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy_gpu(net, data_iter, device=None): \n",
        "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()  # Set the model to evaluation mode\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "    # No. of correct predictions, no. of predictions\n",
        "    metric = d2l.Accumulator(2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(X, list):\n",
        "                # Required for BERT Fine-tuning (to be covered later)\n",
        "                X = [x.to(device) for x in X]\n",
        "            else:\n",
        "                X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
        "    return metric[0] / metric[1]\n"
      ],
      "metadata": {
        "id": "rzZM97SwouTC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
        "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "    net.apply(init_weights)\n",
        "    print('training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    for epoch in range(num_epochs):\n",
        "        # Sum of training loss, sum of training accuracy, no. of examples\n",
        "        metric = d2l.Accumulator(3)\n",
        "        net.train()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad(): # save memory and speed up training\n",
        "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
        "            timer.stop()\n",
        "            train_l = metric[0] / metric[2]\n",
        "            train_acc = metric[1] / metric[2]\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (train_l, train_acc, None))\n",
        "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\n",
        "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
        "          f'test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
        "          f'on {str(device)}')"
      ],
      "metadata": {
        "id": "yyT6NEcApGHh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "C-MANyt6q1B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs = 0.9, 10\n",
        "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "8QwsnBbQpJd3",
        "outputId": "d19a977a-68be-4ee6-eb08-57d4189c6648"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.467, train acc 0.826, test acc 0.728\n",
            "20287.3 examples/sec on cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 238.965625 180.65625\" width=\"238.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 238.965625 180.65625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 51.803125 143.1 \nL 51.803125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8cd22e35e9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.803125\" xlink:href=\"#m8cd22e35e9\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(48.621875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 95.203125 143.1 \nL 95.203125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.203125\" xlink:href=\"#m8cd22e35e9\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(92.021875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 138.603125 143.1 \nL 138.603125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.603125\" xlink:href=\"#m8cd22e35e9\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(135.421875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 182.003125 143.1 \nL 182.003125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.003125\" xlink:href=\"#m8cd22e35e9\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(178.821875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.403125\" xlink:href=\"#m8cd22e35e9\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(219.040625 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(112.525 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 30.103125 142.485985 \nL 225.403125 142.485985 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m969208862c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m969208862c\" y=\"142.485985\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 146.285204)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 30.103125 115.131218 \nL 225.403125 115.131218 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m969208862c\" y=\"115.131218\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 118.930436)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 30.103125 87.77645 \nL 225.403125 87.77645 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m969208862c\" y=\"87.77645\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 91.575669)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 30.103125 60.421683 \nL 225.403125 60.421683 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m969208862c\" y=\"60.421683\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 64.220901)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pfeb6efd883)\" d=\"M 30.103125 33.066915 \nL 225.403125 33.066915 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m969208862c\" y=\"33.066915\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 36.866134)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pfeb6efd883)\" d=\"M 12.743125 13.377273 \nL 17.083125 14.680617 \nL 21.423125 15.196401 \nL 25.763125 15.566361 \nL 30.103125 17.536716 \nL 34.443125 62.161655 \nL 38.783125 70.211196 \nL 43.123125 74.963128 \nL 47.463125 78.290286 \nL 51.803125 80.809467 \nL 56.143125 92.381686 \nL 60.483125 94.426094 \nL 64.823125 95.780527 \nL 69.163125 97.152794 \nL 73.503125 98.237387 \nL 77.843125 102.758748 \nL 82.183125 103.379756 \nL 86.523125 103.908969 \nL 90.863125 104.576083 \nL 95.203125 104.846227 \nL 99.543125 107.288228 \nL 103.883125 107.538286 \nL 108.223125 107.728773 \nL 112.563125 108.015475 \nL 116.903125 108.235028 \nL 121.243125 109.787146 \nL 125.583125 110.14231 \nL 129.923125 110.07581 \nL 134.263125 110.593957 \nL 138.603125 110.702641 \nL 142.943125 111.819634 \nL 147.283125 111.882693 \nL 151.623125 112.249198 \nL 155.963125 112.448784 \nL 160.303125 112.589484 \nL 164.643125 114.004097 \nL 168.983125 114.138454 \nL 173.323125 114.271628 \nL 177.663125 114.545879 \nL 182.003125 114.575702 \nL 186.343125 114.842956 \nL 190.683125 115.397641 \nL 195.023125 115.657036 \nL 199.363125 115.896605 \nL 203.703125 116.078916 \nL 208.043125 116.447782 \nL 212.383125 116.647387 \nL 216.723125 116.528469 \nL 221.063125 116.703821 \nL 225.403125 116.955875 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path clip-path=\"url(#pfeb6efd883)\" d=\"M 12.743125 136.91136 \nL 17.083125 136.922727 \nL 21.423125 136.864374 \nL 25.763125 136.754488 \nL 30.103125 135.385599 \nL 34.443125 120.714937 \nL 38.783125 117.393351 \nL 43.123125 115.422226 \nL 47.463125 113.975142 \nL 51.803125 112.861684 \nL 56.143125 107.810543 \nL 60.483125 106.787468 \nL 64.823125 106.067526 \nL 69.163125 105.538179 \nL 73.503125 105.111166 \nL 77.843125 103.327199 \nL 82.183125 103.284002 \nL 86.523125 102.899781 \nL 90.863125 102.622413 \nL 95.203125 102.513375 \nL 99.543125 101.440193 \nL 103.883125 101.492483 \nL 108.223125 101.394723 \nL 112.563125 101.295825 \nL 116.903125 101.180286 \nL 121.243125 100.54898 \nL 125.583125 100.303442 \nL 129.923125 100.415602 \nL 134.263125 100.1784 \nL 138.603125 100.118921 \nL 142.943125 99.512264 \nL 147.283125 99.541819 \nL 151.623125 99.371307 \nL 155.963125 99.27582 \nL 160.303125 99.236274 \nL 164.643125 98.543752 \nL 168.983125 98.689256 \nL 173.323125 98.619536 \nL 177.663125 98.483504 \nL 182.003125 98.426573 \nL 186.343125 98.139069 \nL 190.683125 98.050402 \nL 195.023125 97.935969 \nL 199.363125 97.84124 \nL 203.703125 97.736321 \nL 208.043125 97.566147 \nL 212.383125 97.391087 \nL 216.723125 97.453987 \nL 221.063125 97.410412 \nL 225.403125 97.304116 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#pfeb6efd883)\" d=\"M 30.103125 128.945375 \nL 51.803125 109.813451 \nL 73.503125 104.380794 \nL 95.203125 102.619147 \nL 116.903125 101.639846 \nL 138.603125 102.542554 \nL 160.303125 100.080624 \nL 182.003125 100.239282 \nL 203.703125 98.253326 \nL 225.403125 102.684798 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 143.1 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 140.634375 59.234375 \nL 218.403125 59.234375 \nQ 220.403125 59.234375 220.403125 57.234375 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 140.634375 12.2 \nQ 138.634375 12.2 138.634375 14.2 \nL 138.634375 57.234375 \nQ 138.634375 59.234375 140.634375 59.234375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 142.634375 20.298438 \nL 162.634375 20.298438 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_12\">\n     <!-- train loss -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(170.634375 23.798438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"292.333984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"353.515625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"405.615234\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 142.634375 34.976562 \nL 162.634375 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_27\"/>\n    <g id=\"text_13\">\n     <!-- train acc -->\n     <g transform=\"translate(170.634375 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"325.830078\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"380.810547\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 142.634375 49.654688 \nL 162.634375 49.654688 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_29\"/>\n    <g id=\"text_14\">\n     <!-- test acc -->\n     <g transform=\"translate(170.634375 53.154688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"285.107422\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"340.087891\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfeb6efd883\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "- In a CNN, convolutional layers are typically arranged so that they grardually decrease the spatial resolution of the representations, while increasing the number of channels\n",
        "- In traditional CNNs, the representations encoded by the convolutional blocks are processed by one or more fully-connected layers prior to emitting output"
      ],
      "metadata": {
        "id": "wGIn6YQkq-8f"
      }
    }
  ]
}